{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGbGLVhCbdTG"
      },
      "outputs": [],
      "source": [
        "#dataset from kagglehub\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"uciml/pima-indians-diabetes-database\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psL3eEAnnjNH"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#dataset loading\n",
        "buffer = path + '/diabetes.csv' #Honestly might as well just attach a local copy of the dataset\n",
        "try:\n",
        "   initial_diabetes = pd.read_csv(buffer)\n",
        "except:\n",
        "   initial_diabetes = pd.read_csv('/diabetes.csv') #Which is what exactly this is for(local copy)\n",
        "\n",
        "#What are the attributes\n",
        "print(\"Dataset Shape:\", initial_diabetes.shape)\n",
        "initial_diabetes.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6aUTwp9tTDb"
      },
      "outputs": [],
      "source": [
        "#Cleaning the data/Preprocessing\n",
        "diabetes = initial_diabetes.dropna() #Removes rows with empty cells(an entirely new DataFrame)\n",
        "diabetes = diabetes.drop_duplicates() #Removes duplicate rows #(inplace = True) will make sure that the method does NOT return a new DataFrame\n",
        "for x in diabetes.index:\n",
        "  if diabetes.loc[x, \"SkinThickness\"] == 0:\n",
        "    diabetes.drop(x, inplace = True)\n",
        "for x in diabetes.index:\n",
        "  if diabetes.loc[x, \"BloodPressure\"] == 0:\n",
        "    diabetes.drop(x, inplace = True)\n",
        "\n",
        "diabetes.tail(70)\n",
        "# diabetes.count()\n",
        "# # Count the number of positive and negative cases\n",
        "# positive_cases = diabetes[diabetes['Outcome'] == 1].shape[0]\n",
        "# negative_cases = diabetes[diabetes['Outcome'] == 0].shape[0]\n",
        "\n",
        "# # Display the counts\n",
        "# print(f\"Number of Positive Cases (Outcome=1): {positive_cases}\")\n",
        "# print(f\"Number of Negative Cases (Outcome=0): {negative_cases}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IUGNEcRwS1B"
      },
      "outputs": [],
      "source": [
        "#Visualize pairplots to see the distribution of attributes for disease outcome\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.pairplot(diabetes, hue='Outcome')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3ytsZZZwy_X"
      },
      "outputs": [],
      "source": [
        "#Box and whiskers\n",
        "print(\"\\nBoxplots of features grouped by target:\")\n",
        "plt.figure(figsize=(15, 30))\n",
        "for i, col in enumerate(diabetes.columns[:-1]):\n",
        "    plt.subplot(4, 2, i+1)\n",
        "    sns.boxplot(x='Outcome', y=col, data=diabetes)\n",
        "    plt.title(f'Boxplot of {col} by Outcome')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8smnevssx9u1"
      },
      "outputs": [],
      "source": [
        "#Preparing x and y\n",
        "x = diabetes.drop(columns=['Outcome']) #Attributes\n",
        "y = diabetes['Outcome'] #Target\n",
        "\n",
        "#Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)\n",
        "#Random State Controls the shuffling applied to the data before applying the split but only if there is even shuffling(Default is true).\n",
        "#Test Size: If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. The Train size not included should be the complement of Test size.\n",
        "\n",
        "#diabetes with column train\n",
        "diabetes_train = {\n",
        "    'attributes': x_train, #attribute table\n",
        "    'target': y_train #target table\n",
        "}\n",
        "\n",
        "#diabetes with column test\n",
        "diabetes_test = {\n",
        "  'attributes': x_test,\n",
        "  'target': y_test\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Grid Search and Bayesian Optimization(Implement both to determine which is better to detect sets of hyperparameters for this model)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, make_scorer\n",
        "!pip install scikit-optimize\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer, Real, Categorical\n",
        "\n",
        "def perform_grid_search(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Perform Grid Search for Decision Tree hyperparameter tuning\n",
        "    \"\"\"\n",
        "    # Define parameter grid or what I think ppl generally call search space\n",
        "    param_grid = {\n",
        "        'max_depth': [1, 5, 8, 13, 21, 34],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4],\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "        'max_features': ['sqrt', 'log2', None]\n",
        "    }\n",
        "\n",
        "    # Create Decision Tree classifier\n",
        "    dtc = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "    # Create GridSearchCV object\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=dtc,\n",
        "        param_grid=param_grid,\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Fit the grid search\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get best model and make predictions\n",
        "    best_grid_model = grid_search.best_estimator_\n",
        "    y_pred_grid = best_grid_model.predict(X_test)\n",
        "\n",
        "    # Return results\n",
        "    return {\n",
        "        'best_params': grid_search.best_params_,\n",
        "        'best_score': grid_search.best_score_,\n",
        "        'test_accuracy': accuracy_score(y_test, y_pred_grid),\n",
        "        'best_model': best_grid_model\n",
        "    }\n",
        "\n",
        "def perform_bayesian_optimization(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Perform Bayesian Optimization for Decision Tree hyperparameter tuning\n",
        "    \"\"\"\n",
        "    # Define search space\n",
        "    search_space = {\n",
        "        'max_depth': Integer(1, 34),\n",
        "        'min_samples_split': Integer(2, 10),\n",
        "        'min_samples_leaf': Integer(1, 4),\n",
        "        'criterion': Categorical(['gini', 'entropy']),\n",
        "        'max_features': Categorical(['sqrt', 'log2', None])\n",
        "    }\n",
        "\n",
        "    # Create Decision Tree classifier\n",
        "    dtc = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "    # Create BayesSearchCV object\n",
        "    bayes_search = BayesSearchCV(\n",
        "        estimator=dtc,\n",
        "        search_spaces=search_space,\n",
        "        n_iter=50,  # Number of iterations\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Fit the Bayesian optimization\n",
        "    bayes_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get best model and make predictions\n",
        "    best_bayes_model = bayes_search.best_estimator_\n",
        "    y_pred_bayes = best_bayes_model.predict(X_test)\n",
        "\n",
        "    # Return results\n",
        "    return {\n",
        "        'best_params': bayes_search.best_params_,\n",
        "        'best_score': bayes_search.best_score_,\n",
        "        'test_accuracy': accuracy_score(y_test, y_pred_bayes),\n",
        "        'best_model': best_bayes_model\n",
        "    }\n",
        "\n",
        "# Run Grid Search\n",
        "grid_results = perform_grid_search(x_train, y_train, x_test, y_test)\n",
        "\n",
        "# Run Bayesian Optimization\n",
        "bayes_results = perform_bayesian_optimization(x_train, y_train, x_test, y_test)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nGrid Search Results:\")\n",
        "print(\"Best parameters:\", grid_results['best_params'])\n",
        "print(\"Best cross-validation score:\", grid_results['best_score'])\n",
        "print(\"Test accuracy:\", grid_results['test_accuracy'])\n",
        "\n",
        "print(\"\\nBayesian Optimization Results:\")\n",
        "print(\"Best parameters:\", bayes_results['best_params'])\n",
        "print(\"Best cross-validation score:\", bayes_results['best_score'])\n",
        "print(\"Test accuracy:\", bayes_results['test_accuracy'])"
      ],
      "metadata": {
        "id": "6NGLh_b1ASqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compare and visualize results between grid and bayesian.\n",
        "def compare_tuning_methods(grid_results, bayes_results):\n",
        "    \"\"\"\n",
        "    Compare and visualize results from both tuning methods\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Create bar plot\n",
        "    methods = ['Grid Search', 'Bayesian Optimization']\n",
        "    train_scores = [grid_results['best_score'], bayes_results['best_score']]\n",
        "    test_scores = [grid_results['test_accuracy'], bayes_results['test_accuracy']]\n",
        "\n",
        "    x = np.arange(len(methods))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.bar(x - width/2, train_scores, width, label='Cross-validation Score')\n",
        "    plt.bar(x + width/2, test_scores, width, label='Test Accuracy')\n",
        "\n",
        "    plt.xlabel('Tuning Method')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Comparison of Hyperparameter Tuning Methods')\n",
        "    plt.xticks(x, methods)\n",
        "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize = 10)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "compare_tuning_methods(grid_results, bayes_results)"
      ],
      "metadata": {
        "id": "ZSFAkNQGBhg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree"
      ],
      "metadata": {
        "id": "dlX1FzqPe70Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VHpork1rkys"
      },
      "outputs": [],
      "source": [
        "#Training portion\n",
        "dtc = DecisionTreeClassifier(**bayes_results['best_params'], random_state=0) #Testing if setting random state to an Int will alter its deterministic nature(It does) (The seed 100 generates a better accuracy result than 0)\n",
        "dtc.fit(diabetes_train['attributes'], diabetes_train['target'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9qvW-y_tITr"
      },
      "outputs": [],
      "source": [
        "#Testing portion\n",
        "predict = dtc.predict(diabetes_test['attributes'])\n",
        "predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkc0wtK9_xMy"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(list(zip(diabetes_test['target'], predict)), columns=['Target', 'Predicted'])\n",
        "#first part of the parameter is data input with indexing, second part is just the columns set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPgpGc2bpm82"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "predictions = dtc.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions)\n",
        "recall = recall_score(y_test, predictions)\n",
        "f1 = f1_score(y_test, predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.3f}')\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization of Results"
      ],
      "metadata": {
        "id": "s264vhjUopz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1-YEZ-Rjem2"
      },
      "outputs": [],
      "source": [
        "#How does the decision tree look like\n",
        "from sklearn.tree import plot_tree\n",
        "plt.figure(figsize=[100,100]) #The visualization is fit automatically to the size of the axis. Use the figsize or dpi arguments of plt.figure to control the size of the rendering.\n",
        "tree = plot_tree(dtc, feature_names=x.columns.tolist(), #class_name not needed since result is binary\n",
        "          filled=True, rounded=True) #filled: When set to True, paint nodes to indicate majority class for classification, extremity of values for regression, or purity of node for multi-output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohHkdJjrrKbs"
      },
      "outputs": [],
      "source": [
        "#Define Colormap for Visualization\n",
        "from matplotlib import cm\n",
        "from matplotlib.colors import ListedColormap\n",
        "colormap = cm.get_cmap('tab20')\n",
        "cm_dark = ListedColormap(colormap.colors[::2])\n",
        "cm_light = ListedColormap(colormap.colors[1::2])\n",
        "\n",
        "#Initialize Accuracy Storage Variables\n",
        "all_acc = []\n",
        "all_acc_cols = []\n",
        "\n",
        "#Generate Feature Combinations\n",
        "att_cols = diabetes_train['attributes'].columns\n",
        "all_comb = []\n",
        "for horiz in att_cols:\n",
        "  for vert in att_cols:\n",
        "    if horiz is vert or [horiz,vert] in all_comb or [vert, horiz] in all_comb:\n",
        "      continue\n",
        "    all_comb.append([horiz, vert])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY2omUHmrMDa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "max_depth = None\n",
        "dtc = DecisionTreeClassifier(random_state=100, max_depth = max_depth)\n",
        "#Iterate through all feature pairs\n",
        "for i, [h,v] in enumerate(all_comb):\n",
        "  fig, ax = plt.subplots(1, 2, figsize = [40,20])\n",
        "\n",
        "  dtc.fit(diabetes_train['attributes'][[h,v]], diabetes_train['target'])\n",
        "  plot_tree(dtc, feature_names = diabetes_train['attributes'][[h,v]].columns.to_list(),\n",
        "            ax=ax[0], filled=True, rounded=True)\n",
        "\n",
        "  x_min = diabetes_train['attributes'][h].min()\n",
        "  x_max = diabetes_train['attributes'][h].max()\n",
        "  x_range = x_max - x_min\n",
        "  x_min = x_min - 0.1 * x_range\n",
        "  x_max = x_max + 0.1 * x_range\n",
        "  y_min = diabetes_train['attributes'][v].min()\n",
        "  y_max = diabetes_train['attributes'][v].max()\n",
        "  y_range = y_max - y_min\n",
        "  y_min = y_min - 0.1 * y_range\n",
        "  y_max = y_max + 0.1 * y_range\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, .01*y_range), np.arange(y_min,y_max, .01*y_range))\n",
        "  z = dtc.predict(list(zip(xx.ravel(), yy.ravel())))\n",
        "  z = z.reshape(xx.shape)\n",
        "\n",
        "  plt.sca(ax[1])\n",
        "  plt.pcolormesh(xx,yy,z,cmap=cm_light)\n",
        "\n",
        "  plt.rcParams.update({'font.size': 30})\n",
        "  ax[1].scatter(diabetes_train['attributes'][h], diabetes_train['attributes'][v],\n",
        "                c=diabetes_train['target'], cmap=cm_dark, s=200,\n",
        "                label='Training data', edgecolor='black', linewidth=1)\n",
        "  ax[1].scatter(diabetes_test['attributes'][h], diabetes_test['attributes'][v],\n",
        "                c=diabetes_test['target'], cmap=cm_dark, s=200,\n",
        "                label = 'Testing data', edgecolor='black', linewidth=1, marker='*')\n",
        "  train_acc = dtc.score(diabetes_train['attributes'][[h,v]], diabetes_train['target'])\n",
        "  test_acc = dtc.score(diabetes_test['attributes'][[h,v]], diabetes_test['target'])\n",
        "  ax[1].set_title(f'training:{train_acc:.3f}, testing:{test_acc:.3f}')\n",
        "  ax[1].set_xlabel(h)\n",
        "  ax[1].set_ylabel(v)\n",
        "  ax[1].legend()\n",
        "\n",
        "  all_acc.append([1, h, v, max_depth, train_acc, test_acc])\n",
        "\n",
        "all_acc_cols = ['i', 'attribute 1', 'attribute 2', 'max depth 1', 'training accuracy 1', 'testing accuracy 1']\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8Z9jPo3rNxk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "max_depth = 3\n",
        "dtc = DecisionTreeClassifier(random_state=100, max_depth = max_depth)\n",
        "for i, [h,v] in enumerate(all_comb):\n",
        "  fig, ax = plt.subplots(1, 2, figsize = [40,20])\n",
        "\n",
        "  dtc.fit(diabetes_train['attributes'][[h,v]], diabetes_train['target'])\n",
        "  plot_tree(dtc, feature_names = diabetes_train['attributes'][[h,v]].columns.to_list(),\n",
        "            ax=ax[0], filled=True, rounded=True)\n",
        "\n",
        "  x_min = diabetes_train['attributes'][h].min()\n",
        "  x_max = diabetes_train['attributes'][h].max()\n",
        "  x_range = x_max - x_min\n",
        "  x_min = x_min - 0.1 * x_range\n",
        "  x_max = x_max + 0.1 * x_range\n",
        "  y_min = diabetes_train['attributes'][v].min()\n",
        "  y_max = diabetes_train['attributes'][v].max()\n",
        "  y_range = y_max - y_min\n",
        "  y_min = y_min - 0.1 * y_range\n",
        "  y_max = y_max + 0.1 * y_range\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, .01*y_range), np.arange(y_min,y_max, .01*y_range))\n",
        "  z = dtc.predict(list(zip(xx.ravel(), yy.ravel())))\n",
        "  z = z.reshape(xx.shape)\n",
        "\n",
        "  plt.sca(ax[1])\n",
        "  plt.pcolormesh(xx,yy,z,cmap=cm_light)\n",
        "\n",
        "  plt.rcParams.update({'font.size': 30})\n",
        "  ax[1].scatter(diabetes_train['attributes'][h], diabetes_train['attributes'][v],\n",
        "                c=diabetes_train['target'], cmap=cm_dark, s=200,\n",
        "                label='Training data', edgecolor='black', linewidth=1)\n",
        "  ax[1].scatter(diabetes_test['attributes'][h], diabetes_test['attributes'][v],\n",
        "                c=diabetes_test['target'], cmap=cm_dark, s=200,\n",
        "                label = 'Testing data', edgecolor='black', linewidth=1, marker='*')\n",
        "  train_acc = dtc.score(diabetes_train['attributes'][[h,v]], diabetes_train['target'])\n",
        "  test_acc = dtc.score(diabetes_test['attributes'][[h,v]], diabetes_test['target'])\n",
        "  ax[1].set_title(f'training:{train_acc:.3f}, testing:{test_acc:.3f}')\n",
        "  ax[1].set_xlabel(h)\n",
        "  ax[1].set_ylabel(v)\n",
        "  ax[1].legend()\n",
        "\n",
        "  all_acc[i] += [max_depth, train_acc, test_acc]\n",
        "\n",
        "all_acc_cols += ['max depth 2', 'training accuracy 2', 'testing accuracy 2']\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5USGj9gb30hI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "max_depths = [1,5,8,13,21,34]\n",
        "training_accuracy =[]\n",
        "testing_accuracy = []\n",
        "for md in max_depths:\n",
        "  dtc = DecisionTreeClassifier(max_depth=md)\n",
        "  dtc.fit(x_train, y_train)\n",
        "  train = dtc.score(x_train, y_train)\n",
        "  test = dtc.score(x_test, y_test)\n",
        "  training_accuracy.append(train)\n",
        "  testing_accuracy.append(test)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.plot(max_depths, training_accuracy, label='training accuracy')\n",
        "plt.plot(max_depths, testing_accuracy, label='testing accuracy')\n",
        "plt.xlabel('max depth')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize = 10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPLMnClTO08c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "max_depths = [1,5,8,13,21,34]\n",
        "plt.figure(figsize=(10, 8))  # Set figure size\n",
        "\n",
        "# Loop through each max_depth\n",
        "for md in max_depths:\n",
        "    dtc = DecisionTreeClassifier(max_depth=md)\n",
        "    dtc.fit(x_train, y_train)\n",
        "\n",
        "    # Predict probabilities for the test set\n",
        "    y_prob = dtc.predict_proba(x_test)[:, 1]  # Probabilities for the positive class #Index Slicing\n",
        "\n",
        "    # Compute the ROC curve and AUC\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_prob, pos_label=None) #pos_label:The label of the positive class. When pos_label=None, if y_true is in {-1, 1} or {0, 1}, pos_label is set to 1, otherwise an error will be raised.\n",
        "    roc_auc = auc(fpr, tpr) #Area under curve\n",
        "\n",
        "    # Plot the ROC curve\n",
        "    plt.plot(fpr, tpr, label=f'max_depth={md}, AUC={roc_auc:.2f}') #true positive, false postive\n",
        "\n",
        "    print(f\"max_depth={md}, AUC={roc_auc:.4f}\")\n",
        "\n",
        "# Plot diagonal line for reference\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Reference')\n",
        "\n",
        "# Add labels, legend, and title\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title('ROC Curve for Different max_depths')\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize = 10)\n",
        "plt.grid()\n",
        "plt.show()\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apNm3bm9vWKW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lsOMJTlrQpl"
      },
      "outputs": [],
      "source": [
        "acc_table = pd.DataFrame(all_acc, columns=['i', 'attribute 1', ' attribute 2', 'max depth 1', ' train accuracy 1', 'test accuracy 1',\n",
        "                                           'max depth 2', 'train accuracy 2', ' test accuracy 2'])\n",
        "acc_table"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "QyJiEXQwi7Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "1KhsGnEWi6b0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "rf_classifier.fit(x_train, y_train)\n",
        "rf_pred = rf_classifier.predict(x_test)"
      ],
      "metadata": {
        "id": "HRQ_X1p1jHdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Get feature importance\n",
        "feature_importances = pd.DataFrame({'Feature': x_train.columns, 'Importance': rf_classifier.feature_importances_})\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importances, palette='Blues_d')\n",
        "plt.title('Feature Importance in Random Forest')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iHM5hbSenHmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "cKO5vjjvoaDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define max_depth values to test\n",
        "max_depths = [1, 5, 8, 13, 21, 34]\n",
        "\n",
        "# Lists to store accuracies\n",
        "training_accuracy = []\n",
        "testing_accuracy = []\n",
        "\n",
        "# Loop through each max_depth\n",
        "for md in max_depths:\n",
        "    rf = RandomForestClassifier(max_depth=md, n_estimators=100, random_state=0)  # Initialize Random Forest\n",
        "    rf.fit(x_train, y_train)  # Fit the model\n",
        "\n",
        "    # Calculate training and testing accuracies\n",
        "    train = rf.score(x_train, y_train)\n",
        "    test = rf.score(x_test, y_test)\n",
        "    training_accuracy.append(train)\n",
        "    testing_accuracy.append(test)\n",
        "\n",
        "# Plot the accuracies\n",
        "plt.tight_layout()\n",
        "plt.plot(max_depths, training_accuracy, label='Training Accuracy')\n",
        "plt.plot(max_depths, testing_accuracy, label='Testing Accuracy')\n",
        "plt.xlabel('Max Depth')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10)\n",
        "plt.title('Training and Testing Accuracy for Random Forest')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UFZFjKaWocYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define max_depth values to test\n",
        "max_depths = [1, 5, 8, 13, 21, 34]\n",
        "plt.figure(figsize=(10, 8))  # Set figure size\n",
        "\n",
        "# Loop through each max_depth\n",
        "for md in max_depths:\n",
        "    # Initialize and fit Random Forest with specific max_depth\n",
        "    rf = RandomForestClassifier(max_depth=md, n_estimators=100, random_state=0)\n",
        "    rf.fit(x_train, y_train)\n",
        "\n",
        "    # Predict probabilities for the positive class\n",
        "    y_prob = rf.predict_proba(x_test)[:, 1]\n",
        "\n",
        "    # Compute the ROC curve and AUC\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Plot the ROC curve\n",
        "    plt.plot(fpr, tpr, label=f'max_depth={md}, AUC={roc_auc:.2f}')\n",
        "    print(f\"max_depth={md}, AUC={roc_auc:.4f}\")  # Log AUC for each depth\n",
        "\n",
        "# Plot diagonal line for reference\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Reference')\n",
        "\n",
        "# Add labels, legend, and title\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title('ROC Curve for Random Forest with Different max_depths')\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10)\n",
        "plt.grid()\n",
        "plt.tight_layout()  # Adjust layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wp0zY_xIpN8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, rf_pred)\n",
        "precision = precision_score(y_test, rf_pred)\n",
        "recall = recall_score(y_test, rf_pred)\n",
        "f1 = f1_score(y_test, rf_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.3f}')\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")"
      ],
      "metadata": {
        "id": "AxpfzYnKjjHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, rf_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yipQD-KYpptj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM"
      ],
      "metadata": {
        "id": "NXZ8B8_P5Dub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "-TbO_9Aq5F0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='rbf', probability=True, random_state=0)\n",
        "svm.fit(x_train, y_train)\n",
        "svm_pred = svm.predict(x_test)"
      ],
      "metadata": {
        "id": "v9x-44vE5K4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Train SVM on two features (for 2D visualization)\n",
        "svm = SVC(kernel='linear', C=1)\n",
        "svm.fit(x_train.iloc[:, :2], y_train)  # Using only the first two features for simplicity\n",
        "\n",
        "# Create a mesh grid\n",
        "x_min, x_max = x_train.iloc[:, 0].min() - 1, x_train.iloc[:, 0].max() + 1\n",
        "y_min, y_max = x_train.iloc[:, 1].min() - 1, x_train.iloc[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
        "\n",
        "# Predict on grid points\n",
        "Z = svm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot the decision boundary\n",
        "plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Paired)\n",
        "plt.scatter(x_train.iloc[:, 0], x_train.iloc[:, 1], c=y_train, edgecolors='k', cmap=plt.cm.Paired)\n",
        "plt.title(\"SVM Decision Boundary\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "56cEe8C-7aRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "Ax96bAh77blQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Define C values to test (regularization parameter)\n",
        "C_values = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# Lists to store accuracies\n",
        "training_accuracy = []\n",
        "testing_accuracy = []\n",
        "\n",
        "# Loop through each C value\n",
        "for c in C_values:\n",
        "    svm = SVC(C=c, kernel='linear', random_state=0)  # Initialize SVM with RBF kernel\n",
        "    svm.fit(x_train, y_train)  # Fit the model\n",
        "\n",
        "    # Calculate training and testing accuracies\n",
        "    train = svm.score(x_train, y_train)\n",
        "    test = svm.score(x_test, y_test)\n",
        "    training_accuracy.append(train)\n",
        "    testing_accuracy.append(test)\n",
        "\n",
        "# Plot the accuracies\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(C_values, training_accuracy, marker='o', label='Training Accuracy')\n",
        "plt.plot(C_values, testing_accuracy, marker='s', label='Testing Accuracy')\n",
        "plt.xscale('log')  # Use a logarithmic scale for C values\n",
        "plt.xlabel('C (Regularization Parameter)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Testing Accuracy for SVM with Different C Values')\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10)\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rkttkkd1u-qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "kernels = ['linear', 'rbf', 'poly']\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for kernel in kernels:\n",
        "    # Initialize and fit SVM with the specific kernel\n",
        "    svm = SVC(kernel=kernel, C=1, probability=True, random_state=0)\n",
        "    svm.fit(x_train, y_train)\n",
        "\n",
        "    # Predict probabilities for the positive class\n",
        "    y_prob = svm.predict_proba(x_test)[:, 1]\n",
        "\n",
        "    # Compute the ROC curve and AUC\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Plot the ROC curve\n",
        "    plt.plot(fpr, tpr, label=f'kernel={kernel}, AUC={roc_auc:.2f}')\n",
        "    print(f\"kernel={kernel}, AUC={roc_auc:.4f}\")  # Log AUC for each kernel\n",
        "\n",
        "# Plot diagonal line for reference\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Reference')\n",
        "\n",
        "# Add labels, legend, and title\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title('ROC Curve for SVM with Different Kernels')\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10)\n",
        "plt.grid()\n",
        "plt.tight_layout()  # Adjust layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y8s4iOCj59gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, svm_pred)\n",
        "precision = precision_score(y_test, svm_pred)\n",
        "recall = recall_score(y_test, svm_pred)\n",
        "f1 = f1_score(y_test, svm_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.3f}')\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")"
      ],
      "metadata": {
        "id": "BeZ6w7sZ5W4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hvrbMGBs5r3p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}